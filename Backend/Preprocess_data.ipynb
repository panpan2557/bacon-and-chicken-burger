{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Preprocess Giant Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data From csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "directory = './Result/'\n",
    "files = os.listdir(directory)\n",
    "\n",
    "df = pd.concat([pd.read_csv(directory + f, \n",
    "                            usecols=[\"Gender\", \"BirthDate\", \"AdmissionDate\", \"DischargeDate\", \"Postcode\", \"Drg\", \"Cpt\", \"ServiceDate\", \"Charges\"],\n",
    "                            dtype={'Postcode': 'str', 'Drg': 'str', 'Cpt': 'str', 'BirthDate': 'str'},\n",
    "                           ) for f in files], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create postcode dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = './data/free-zipcode-database.csv'\n",
    "df_postcode = pd.read_csv(file, usecols=[\"Zipcode\", \"State\"])\n",
    "pos_dict = df_postcode.to_dict(orient='split')\n",
    "pos_dictionaray = {}\n",
    "for pos_list in pos_dict['data']:\n",
    "    pos_dictionaray[str(pos_list[0])] = pos_list[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 119042455 entries, 0 to 119042454\n",
      "Data columns (total 9 columns):\n",
      "Gender           object\n",
      "BirthDate        object\n",
      "AdmissionDate    object\n",
      "DischargeDate    object\n",
      "Postcode         object\n",
      "Drg              object\n",
      "Cpt              object\n",
      "ServiceDate      object\n",
      "Charges          object\n",
      "dtypes: object(9)\n",
      "memory usage: 8.0+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter and Parse columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseZip(zipcode):\n",
    "    first_five = zipcode[:5]\n",
    "    try:\n",
    "        #   add leading zeroe\n",
    "        code = '{:05}'.format(int(first_five))\n",
    "        result = pos_dictionaray[code]\n",
    "        if result:\n",
    "            return result\n",
    "        return 'null'\n",
    "    except:\n",
    "        return 'null'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseYear(date):\n",
    "    try:\n",
    "        year = date.split('/')[2]\n",
    "    except:\n",
    "        return date\n",
    "    return year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseCharges(charge):\n",
    "    new_charge = [x for x in charge if x.isdigit() or x == '.']\n",
    "    return float(\"\".join(new_charge))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Postcode'] = df['Postcode'].apply(lambda row: parseZip(row))\n",
    "df['ServiceDate'] = df['ServiceDate'].apply(lambda row: parseYear(row))\n",
    "df['Charges'] = df['Charges'].apply(lambda row: parseCharges(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_year = df.groupby(['ServiceDate', 'Gender']).size()\n",
    "group_by_postcode = df.groupby(['ServiceDate','Postcode']).size()\n",
    "group_by_charges = df.groupby(['ServiceDate','Postcode']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert pandas sequence to python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gender_mapping = group_by_year.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_mapping = group_by_postcode.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "charges_mapping = group_by_charges.to_dict()\n",
    "charges_mapping = charges_mapping['Charges']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Process dictionaries into one big dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "giant_data = {}\n",
    "# do heat map first\n",
    "HEAT_MAP = 'heatmap'\n",
    "for key_tuple in state_mapping:\n",
    "    year = key_tuple[0].strip()\n",
    "    state = (\"US-\"+key_tuple[1].strip()).upper()\n",
    "    if year not in giant_data:\n",
    "        giant_data[year] = dict()\n",
    "    if HEAT_MAP not in giant_data[year]:\n",
    "        giant_data[year][HEAT_MAP] = dict()\n",
    "    if state not in giant_data[year][HEAT_MAP]:\n",
    "        giant_data[year][HEAT_MAP][state] = 0\n",
    "    giant_data[year][HEAT_MAP][state] += int(state_mapping[key_tuple])\n",
    "    \n",
    "#then do stats\n",
    "STATS = 'stats'\n",
    "TOTAL_CASES = 'totalCases'\n",
    "for key_tuple in gender_mapping:\n",
    "    year = key_tuple[0]\n",
    "    gender = key_tuple[1]\n",
    "    if year not in giant_data:\n",
    "        giant_data[year] = dict()\n",
    "    if STATS not in giant_data[year]:\n",
    "        giant_data[year][STATS] = dict()\n",
    "        giant_data[year][STATS][TOTAL_CASES] = 0\n",
    "        giant_data[year][STATS]['M'] = 0\n",
    "        giant_data[year][STATS]['F'] = 0\n",
    "    giant_data[year][STATS][TOTAL_CASES] += int(gender_mapping[key_tuple])\n",
    "    giant_data[year][STATS][gender] += int(gender_mapping[key_tuple])\n",
    "\n",
    "#Add ACPC\n",
    "HEAT_MAP_ACPC = 'heatmapAcpc'\n",
    "for key_tuple in charges_mapping:\n",
    "    year = key_tuple[0]\n",
    "    state = (\"US-\"+key_tuple[1].strip()).upper()\n",
    "    if year not in giant_data:\n",
    "        giant_data[year] = dict()\n",
    "    if HEAT_MAP_ACPC not in giant_data[year]:\n",
    "        giant_data[year][HEAT_MAP_ACPC] = dict()\n",
    "    if state not in giant_data[year][HEAT_MAP_ACPC]:\n",
    "        giant_data[year][HEAT_MAP_ACPC][state] = 0\n",
    "    giant_data[year][HEAT_MAP_ACPC][state] += float(charges_mapping[key_tuple]) / giant_data[year][HEAT_MAP][state]\n",
    "\n",
    "    \n",
    "    \n",
    "#Get top 5\n",
    "TOP_HIGH = 'topHigh'\n",
    "TOP_LOW = 'topLow'\n",
    "TOP_HIGH_ACPC = 'topHighAcpc'\n",
    "TOP_LOW_ACPC = 'topLowAcpc'\n",
    "DELETED_KEY = 'US-NULL'\n",
    "for year in giant_data:\n",
    "    states = dict(giant_data[year][HEAT_MAP])\n",
    "    if DELETED_KEY in states:\n",
    "        del states[DELETED_KEY]\n",
    "        \n",
    "    sorted_states = sorted(states.items(), key=operator.itemgetter(1))\n",
    "    giant_data[year][STATS][TOP_LOW] = sorted_states[:5]\n",
    "    giant_data[year][STATS][TOP_HIGH] = sorted_states[::-1][:5]\n",
    "    \n",
    "    acpc = dict(giant_data[year][HEAT_MAP_ACPC])\n",
    "    if DELETED_KEY in states:\n",
    "        del states[DELETED_KEY]\n",
    "    \n",
    "    sorted_acpc = sorted(acpc.items(), key=operator.itemgetter(1))\n",
    "    giant_data[year][STATS][TOP_LOW_ACPC] = sorted_acpc[:5]\n",
    "    giant_data[year][STATS][TOP_HIGH_ACPC] = sorted_acpc[::-1][:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export Dictionary to json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open ('giant_data_file.json','w+') as f:\n",
    "    json.dump(giant_data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
